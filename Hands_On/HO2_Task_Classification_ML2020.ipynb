{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marziyeh-sa/Machine_Learning_Fall2020/blob/main/Hands_On/HO2_Task_Classification_ML2020.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvA4gBkXztHN"
      },
      "source": [
        "![alt text](Capture8.png \"Title\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prNhBbj0ztHU"
      },
      "source": [
        "###  <font color=red>Working with MNIST Dataset</font> ###"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_sG_Y2QztHY"
      },
      "source": [
        "__In this question, you are given the MNIST dataset, which consists of 70,000 images of digits handwritten by students and employees of US Census Bureau.__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkWNhYOsztHb"
      },
      "source": [
        "You are supposed to perform a binary classification task, separating digit 4 from others (0,1,2,3,5,6,7,8,9). The data could be downloaded using the code below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oipczLoE3khe"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpoZBzX0ztHe"
      },
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "\n",
        "# This will take less than a minute to run.\n",
        "\n",
        "X, y = fetch_openml('mnist_784', version=1, return_X_y=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFoZagmrztH0"
      },
      "source": [
        "### <font color=green>1:</font> ###\n",
        "\n",
        "__In the first step, you are going to get acquainted with the dataset.__\n",
        "\n",
        "Randomly, plot three digits from the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6MLFinX5H_-"
      },
      "source": [
        "rnd = np.random.randint(1,len(X),3)\n",
        "\n",
        "for i in range(3):\n",
        "    img = X[rnd[i]].reshape((28,28))\n",
        "    plt.imshow(img, cmap=\"Greys\")\n",
        "    plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UoasgVVhztID"
      },
      "source": [
        "### <font color=green>2:</font> ###\n",
        "__In the second step, you should build your dataset. Do as follows:__\n",
        "* Split your training and testing dataset (80% and 20%).\n",
        "* Set the random_state to 10.\n",
        "* As your goal is to identify digit 4, create the target vectors for this classification task  <font color=red>(note that you are training a binary classifier)</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MM9em0yVztIF"
      },
      "source": [
        "# split data \n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfR0547U6Ea0"
      },
      "source": [
        "y_train_4 = (y_train == 4)\n",
        "y_test_4 = (y_test == 4)\n",
        "print (y_train_4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bz_81ISQztIY"
      },
      "source": [
        "### <font color=green>3:</font> ###\n",
        "__Do the classification task using a <font color=red>Gaussian Naive Bayes Classifier</font>__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9LXNDsOztIa"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB   \n",
        "\n",
        "clf = GaussianNB()  \n",
        "\n",
        "# fitting the classifier\n",
        "clf.fit(X_train, y_train_4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7swWzHc3_BXl"
      },
      "source": [
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print(\"The accuracy of the model is: %.1f%%\" % (accuracy_score(y_test, y_pred)*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2WXbKKVztI1"
      },
      "source": [
        "### <font color=green>4:</font> ###\n",
        "__Calculate the following values:__\n",
        "* Confusion Matrix\n",
        "* Accuracy\n",
        "* Sensitivity\n",
        "* Specificity\n",
        "* Precision\n",
        "* Recall"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clGlJ4aWztI5"
      },
      "source": [
        "# Confusion Matrix\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "confusion_mtx = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(confusion_mtx)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0qrSt0s_V_t"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import itertools\n",
        "\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize = (5,5))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=90)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAlidkllA4g8"
      },
      "source": [
        "class_names = ['0','1','2','3','4','5','6','7','8','9']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mmqjdVr_h0p"
      },
      "source": [
        "plot_confusion_matrix(confusion_mtx, class_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYILlx1mCeR0"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_test, y_pred, target_names=class_names))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSvNgTeqJ_Tp"
      },
      "source": [
        "# 2\n",
        "\n",
        "FP = confusion_mtx.sum(axis=0) - np.diag(confusion_mtx)  \n",
        "FN = confusion_mtx.sum(axis=1) - np.diag(confusion_mtx)\n",
        "TP = np.diag(confusion_mtx)\n",
        "TN = confusion_mtx.sum() - (FP + FN + TP)\n",
        "\n",
        "# Sensitivity, hit rate, recall, or true positive rate\n",
        "Sensitivity = TP/(TP+FN)\n",
        "# Specificity or true negative rate\n",
        "Specificity = TN/(TN+FP) \n",
        "# Precision or positive predictive value\n",
        "Precision = TP/(TP+FP)\n",
        "#Recall and sensitivity are one and the same\n",
        "Recall = TP/(TP+FN)\n",
        "# Negative predictive value\n",
        "NPV = TN/(TN+FN)\n",
        "# Fall out or false positive rate\n",
        "FPR = FP/(FP+TN)\n",
        "# False negative rate\n",
        "FNR = FN/(TP+FN)\n",
        "# False discovery rate\n",
        "FDR = FP/(TP+FP)\n",
        "\n",
        "# Overall accuracy\n",
        "ACC = (TP+TN)/(TP+FP+FN+TN)\n",
        "print ('Accuracy = ',ACC)\n",
        "print ('Sensitivity = ',Sensitivity)\n",
        "print ('Specificity = ', Specificity)\n",
        "print ('Precision = ', Precision)\n",
        "print ('Recall = ', Recall)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YL5livueztJM"
      },
      "source": [
        "### <font color=green>5:</font> ###\n",
        "__Now plot <font color=red>the ROC curve</font>, then calculate <font color=red>Area Under ROC (AUROC)</font>__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqhrS3LsTzZq"
      },
      "source": [
        "\n",
        "y_t = np.array([v.replace(',', '') for v in y_test], dtype=np.float32)\n",
        "y_p = np.array([v.replace(',', '') for v in y_pred], dtype=np.float32)\n",
        " yt  = y_test.astype(np.float)\n",
        "print (y_test)\n",
        "print(yt)\n",
        "print(y_p)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHK2kpinztJP"
      },
      "source": [
        "from sklearn.metrics import  roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "def plot_ROC (y_test , y_pred):\n",
        "    logit_roc_auc  = roc_auc_score(y_test , y_pred  ,  multi_class='ovo',average='macro')\n",
        "    # calculate roc curve\n",
        "    fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
        "    plt.figure()\n",
        "    plt.plot(fpr ,tpr , label = ' Guassian Naive bays (area = %0.2f)' %logit_roc_auc)\n",
        "    plt.plot([0 , 1],[0 , 1], 'r--')\n",
        "    plt.ylim([0.0 ,1.05])\n",
        "    plt.xlim([0.0 ,1.0])\n",
        "    plt.xlabel('False posetive Rate')\n",
        "    plt.ylabel('True posetive Rate')\n",
        "    plt.title('Receiver Operating Characteristic')\n",
        "    plt.legend(loc = \"lower right\")\n",
        "    plt.savefig('Log_ROC')\n",
        "    plt.show\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RREtDQNpwJ_A"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "yy = pd.DataFrame(y_t)\n",
        "yy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gisIL2tbRvER"
      },
      "source": [
        "\n",
        "plot_ROC(yy , y_p )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wQrQPjU5LVs"
      },
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(y_train_5,y_scores)\n",
        "\n",
        "def plot_roc_curve(fpr, tpr, label=None):\n",
        "    plt.figure(figsize=(12,8))\n",
        "    plt.title('ROC curve')\n",
        "    plt.plot(fpr, tpr, linewidth=2, label=label)\n",
        "    plt.plot([0,1],[0,1],\"k--\")\n",
        "    plt.xlim([0,1])\n",
        "    plt.ylim([0,1])\n",
        "    plt.xlabel('False positive rate')\n",
        "    plt.ylabel('True positive rate')\n",
        "\n",
        "plot_roc_curve(fpr,tpr)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5ixC53s4MeG"
      },
      "source": [
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.metrics import roc_auc_score\n",
        "myscore = make_scorer(roc_auc_score, multi_class='ovo',needs_proba=True)\n",
        "myscore"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJKw36Unai5x"
      },
      "source": [
        "ns_probs = [0 for _ in range(len(y_t))]\n",
        "# calculate scores\n",
        "ns_auc = roc_auc_score(y_t, ns_probs , multi_class='ovo')\n",
        "lr_auc = roc_auc_score(y_t, y_p , multi_class='ovo')\n",
        "# summarize scores\n",
        "print('No Skill: ROC AUC=%.3f' % (ns_auc))\n",
        "print('Logistic: ROC AUC=%.3f' % (lr_auc))\n",
        "# calculate roc curves\n",
        "ns_fpr, ns_tpr, _ = roc_curve(y_t, ns_probs)\n",
        "lr_fpr, lr_tpr, _ = roc_curve(y_t, y_p)\n",
        "# plot the roc curve for the model\n",
        "pyplot.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')\n",
        "pyplot.plot(lr_fpr, lr_tpr, marker='.', label='Logistic')\n",
        "# axis labels\n",
        "pyplot.xlabel('False Positive Rate')\n",
        "pyplot.ylabel('True Positive Rate')\n",
        "# show the legend\n",
        "pyplot.legend()\n",
        "# show the plot\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csEjV7CpSXjA"
      },
      "source": [
        "from sklearn import multi_class_series \n",
        "\n",
        "label = class_names\n",
        "roc = {label: [] for label in multi_class_series.unique()}\n",
        "for label in multi_class_series.unique():\n",
        "    roc[label] += roc_auc_score(y_test, y_pred[:,1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7hDbrelPEF4"
      },
      "source": [
        "# calculate AUC\n",
        "auc = roc_auc_score(y_test, y_pred)\n",
        "print('AUC: %.3f' % auc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zf25Hz40ztJk"
      },
      "source": [
        "### <font color=green>6:</font> ###\n",
        "__Finally, apply a 5-fold cross validation, and report your <font color=red>mean and std values</font>.__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWppLVrwztJr"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "acc = cross_val_score(clf, X, y, cv=5, scoring='accuracy')\n",
        "print(acc)\n",
        "\n",
        "print(\"Our accuracy is: %.2f%% +- %.2f%%\" %(np.mean(acc)*100,np.std(acc)*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oHEY_MeztJ7"
      },
      "source": [
        "### <font color=green>7:</font> ###\n",
        "__How are your results?__\n",
        "\n",
        "__Is <font color=red>Gaussian Naive Bayes Classifier</font> a good one for this problem?__\n",
        "\n",
        " خیر ؛ همان گونه که مشاهده میکنیم دقت ما در این روش طبقه بند بسیار پایین است  وخطا بالاست  با مشاهده  خطای ولیدیشن میز مشاهده میکینم خطا بالاست "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntoTpRN8ztJ-"
      },
      "source": [
        "### __Repeat all the steps using <font color=green>Nearest Centroid Classifier</font> and <font color=green>Logistic Regression Classifier</font>.__ ### \n",
        "* You just need to make some changes to step 3!\n",
        "* You should report all the values in steps 4, 5, and 6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KdmIEXsOztKC"
      },
      "source": [
        "### __Which one is better? Report it.__ ###"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TrRXagoFztKH"
      },
      "source": [
        "_________________________________________________________"
      ]
    }
  ]
}